{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of GNN models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gnn_torch_utils' from '../pred_models/gnn_torch_utils.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# import util scripts\n",
    "# add path\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../pred_models/')\n",
    "\n",
    "import pred_utils\n",
    "import gnn_torch_utils\n",
    "import gnn_torch_models\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gnn_torch_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PCC', 'STTC', 'CCH'])\n",
      "dict_keys(['t1', 't2'])\n",
      "dict_keys(['nodes', 'fc_graphs', 'target_fr', 'chip_ids'])\n"
     ]
    }
   ],
   "source": [
    "# load-in data\n",
    "\n",
    "dataset = np.load('../data/dataset.npy', allow_pickle=True).item()\n",
    "print(dataset.keys())\n",
    "print(dataset['PCC'].keys())\n",
    "print(dataset['PCC']['t1'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'dataset' stores all the data used for the prediction task. <br>\n",
    "e.g.) dataset['PCC']['t1'] -> dataset for PCC and task1.\n",
    "\n",
    "'nodes' -> node features (waveform features, firing pattern features) <br>\n",
    "'fc_graphs'-> FC graphs <br>\n",
    "'target_fr' -> fold-changes in differential firing rates <br>\n",
    "'chip_ids' -> Microelectrode array id for each network. Used for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection (grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_prob': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# grid search with nested leave-one-out cross validation\n",
    "# Here we only put scripts to perform the grid search and we have uploaded the best parameter found after running this script.  \n",
    "\n",
    "# grid search parameters \n",
    "dropout_probs = [0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "l2_regs = [1e-4, 1e-3, 1e-2] \n",
    "hidden_dims = [8, 16, 32]\n",
    "\n",
    "#generate parameter sets\n",
    "fit_param_list = gnn_torch_utils.gen_gridparams(dropout_probs, learning_rates, l2_regs, hidden_dims)\n",
    "\n",
    "print(fit_param_list[0]) # print only the first parameter entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PCC task1 as an example \n",
    "\n",
    "# load in dataset\n",
    "nodes = dataset['PCC']['t1']['nodes']\n",
    "FCs = dataset['PCC']['t1']['fc_graphs']\n",
    "target_frs = dataset['PCC']['t1']['target_fr']\n",
    "chip_ids = dataset['PCC']['t1']['chip_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep. step for the nested cross validation \n",
    "\n",
    "# split dataset \n",
    "full_index= np.arange(len(target_frs)) # getting indices\n",
    "\n",
    "#get unique chip ids  (we have 24 networks from 8 different unique chips (for the undirected FC case))\n",
    "uniq_chip = np.unique(chip_ids)\n",
    "\n",
    "#sample one index per chip\n",
    "uniq_indices=[] \n",
    "for uniq_c in uniq_chip:\n",
    "    indices = np.where(np.array(chip_ids)==uniq_c)[0]\n",
    "    uniq_indices.append(indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_acc: 1.0694, validate_acc : 0.5342, LR : 0.00100000\n",
      "Epoch: 50, train_acc: 0.9794, validate_acc : 0.3834, LR : 0.00100000\n",
      "Epoch: 100, train_acc: 0.9293, validate_acc : 0.3505, LR : 0.00100000\n",
      "Epoch: 150, train_acc: 0.8982, validate_acc : 0.3337, LR : 0.00100000\n",
      "Epoch: 200, train_acc: 0.8810, validate_acc : 0.3252, LR : 0.00100000\n",
      "Epoch: 250, train_acc: 0.8694, validate_acc : 0.3191, LR : 0.00100000\n",
      "Epoch: 300, train_acc: 0.8599, validate_acc : 0.3146, LR : 0.00100000\n",
      "Epoch: 350, train_acc: 0.8498, validate_acc : 0.3136, LR : 0.00100000\n",
      "Epoch: 400, train_acc: 0.8414, validate_acc : 0.3108, LR : 0.00100000\n",
      "Epoch: 450, train_acc: 0.8335, validate_acc : 0.3108, LR : 0.00100000\n",
      "Epoch: 500, train_acc: 0.8254, validate_acc : 0.3108, LR : 0.00100000\n",
      "Epoch: 550, train_acc: 0.8181, validate_acc : 0.3093, LR : 0.00100000\n",
      "Epoch: 600, train_acc: 0.8114, validate_acc : 0.3055, LR : 0.00100000\n",
      "Epoch: 650, train_acc: 0.8055, validate_acc : 0.3075, LR : 0.00100000\n",
      "Epoch: 700, train_acc: 0.7990, validate_acc : 0.3131, LR : 0.00100000\n",
      "Epoch: 750, train_acc: 0.7923, validate_acc : 0.3118, LR : 0.00100000\n",
      "Epoch: 800, train_acc: 0.7861, validate_acc : 0.3113, LR : 0.00100000\n",
      "Epoch: 850, train_acc: 0.7786, validate_acc : 0.3147, LR : 0.00100000\n",
      "Epoch: 900, train_acc: 0.7711, validate_acc : 0.3137, LR : 0.00100000\n",
      "Epoch: 950, train_acc: 0.7644, validate_acc : 0.3105, LR : 0.00100000\n",
      "iteration: 0, test_acc: 0.3074\n",
      "Epoch: 0, train_acc: 1.0558, validate_acc : 0.1987, LR : 0.00100000\n",
      "Epoch: 50, train_acc: 0.9900, validate_acc : 0.1622, LR : 0.00100000\n",
      "Epoch: 100, train_acc: 0.9395, validate_acc : 0.1448, LR : 0.00100000\n",
      "Epoch: 150, train_acc: 0.8987, validate_acc : 0.1374, LR : 0.00100000\n",
      "Epoch: 200, train_acc: 0.8717, validate_acc : 0.1409, LR : 0.00100000\n",
      "Epoch: 250, train_acc: 0.8532, validate_acc : 0.1370, LR : 0.00100000\n",
      "Epoch: 300, train_acc: 0.8388, validate_acc : 0.1296, LR : 0.00100000\n",
      "Epoch: 350, train_acc: 0.8270, validate_acc : 0.1229, LR : 0.00100000\n",
      "Epoch: 400, train_acc: 0.8175, validate_acc : 0.1129, LR : 0.00100000\n",
      "Epoch: 450, train_acc: 0.8080, validate_acc : 0.1094, LR : 0.00100000\n",
      "Epoch: 500, train_acc: 0.7997, validate_acc : 0.1170, LR : 0.00100000\n",
      "Epoch: 550, train_acc: 0.7926, validate_acc : 0.1224, LR : 0.00100000\n",
      "Epoch: 600, train_acc: 0.7871, validate_acc : 0.1221, LR : 0.00100000\n",
      "Epoch: 650, train_acc: 0.7823, validate_acc : 0.1192, LR : 0.00100000\n",
      "Epoch: 700, train_acc: 0.7766, validate_acc : 0.1153, LR : 0.00100000\n",
      "Epoch: 750, train_acc: 0.7717, validate_acc : 0.1138, LR : 0.00100000\n",
      "Epoch: 800, train_acc: 0.7672, validate_acc : 0.1121, LR : 0.00100000\n",
      "Epoch: 850, train_acc: 0.7632, validate_acc : 0.1075, LR : 0.00100000\n",
      "Epoch: 900, train_acc: 0.7594, validate_acc : 0.1024, LR : 0.00100000\n",
      "Epoch: 950, train_acc: 0.7561, validate_acc : 0.0994, LR : 0.00100000\n",
      "iteration: 0, test_acc: 0.0988\n",
      "Epoch: 0, train_acc: 1.1144, validate_acc : 1.3112, LR : 0.00100000\n",
      "Epoch: 50, train_acc: 1.0094, validate_acc : 1.1451, LR : 0.00100000\n",
      "Epoch: 100, train_acc: 0.9766, validate_acc : 1.1217, LR : 0.00100000\n",
      "Epoch: 150, train_acc: 0.9480, validate_acc : 1.0941, LR : 0.00100000\n",
      "Epoch: 200, train_acc: 0.9195, validate_acc : 1.0609, LR : 0.00100000\n",
      "Epoch: 250, train_acc: 0.8870, validate_acc : 1.0290, LR : 0.00100000\n",
      "Epoch: 300, train_acc: 0.8585, validate_acc : 1.0145, LR : 0.00100000\n",
      "Epoch: 350, train_acc: 0.8367, validate_acc : 1.0088, LR : 0.00100000\n",
      "Epoch: 400, train_acc: 0.8212, validate_acc : 1.0049, LR : 0.00100000\n",
      "Epoch: 450, train_acc: 0.8113, validate_acc : 1.0000, LR : 0.00100000\n",
      "Epoch: 500, train_acc: 0.8041, validate_acc : 0.9928, LR : 0.00100000\n",
      "Epoch: 550, train_acc: 0.7975, validate_acc : 0.9834, LR : 0.00100000\n",
      "Epoch: 600, train_acc: 0.7914, validate_acc : 0.9814, LR : 0.00100000\n",
      "Epoch: 650, train_acc: 0.7864, validate_acc : 0.9750, LR : 0.00100000\n",
      "Epoch: 700, train_acc: 0.7806, validate_acc : 0.9772, LR : 0.00100000\n",
      "Epoch: 750, train_acc: 0.7752, validate_acc : 0.9718, LR : 0.00100000\n",
      "Epoch: 800, train_acc: 0.7700, validate_acc : 0.9671, LR : 0.00100000\n",
      "Epoch: 850, train_acc: 0.7658, validate_acc : 0.9607, LR : 0.00100000\n",
      "Epoch: 900, train_acc: 0.7616, validate_acc : 0.9568, LR : 0.00100000\n",
      "Epoch: 950, train_acc: 0.7583, validate_acc : 0.9544, LR : 0.00100000\n",
      "iteration: 0, test_acc: 0.9537\n",
      "Epoch: 0, train_acc: 0.9910, validate_acc : 2.0067, LR : 0.00100000\n",
      "Epoch: 50, train_acc: 0.9405, validate_acc : 1.9127, LR : 0.00100000\n",
      "Epoch: 100, train_acc: 0.9195, validate_acc : 1.9301, LR : 0.00100000\n",
      "Epoch: 150, train_acc: 0.8986, validate_acc : 1.9381, LR : 0.00100000\n",
      "Epoch: 200, train_acc: 0.8762, validate_acc : 1.9335, LR : 0.00100000\n",
      "Epoch: 250, train_acc: 0.8513, validate_acc : 1.9420, LR : 0.00100000\n",
      "Epoch: 300, train_acc: 0.8302, validate_acc : 1.9533, LR : 0.00100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4c5fcad0c0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# this line runs the inner loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgcn_result\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgnn_torch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_gridsearch_batch_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFCs_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_frs_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_param_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchip_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mfor_each_test_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_result\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# collect the result of the inner loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work_directory/wp1_github/gnn_prediction_sn/pred_models/gnn_torch_utils.py\u001b[0m in \u001b[0;36mrun_gridsearch_batch_x\u001b[0;34m(nodes, FCs, target_frs, epoch_n, iter_n, model_string, fit_param_list, device, chip_ids)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_dims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_dims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_GNN_batch_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_frs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchip_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfit_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work_directory/wp1_github/gnn_prediction_sn/pred_models/gnn_torch_utils.py\u001b[0m in \u001b[0;36mrun_GNN_batch_x\u001b[0;34m(nodes, FCs, target_frs, n_epoch, iter_n, model_string, fit_params_list, device, chip_ids, gridsearch)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forwarding x has 0 for single wfs defected ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main outer-inner loop\n",
    "for_each_test_idx = [] # placeholder to collect resulting MSEs (outer loop)\n",
    "for ii in uniq_indices: # we will not only take out the test network but also all networks that belong to the same chip for each inner loop. \n",
    "    same_chip = np.where(np.array(chip_ids) == chip_ids[ii])[0] \n",
    "    use_idx = np.setxor1d(full_index, same_chip)\n",
    "    \n",
    "    nodes_inner = np.array(nodes, dtype=object)[use_idx]\n",
    "    FCs_inner = np.array(FCs,dtype=object)[use_idx]\n",
    "    target_frs_inner = np.array(target_frs,dtype=object)[use_idx]\n",
    "    \n",
    "    \n",
    "    # some parameters for running the grid search\n",
    "    epochs = 1000 # we used 1000 for the paper. \n",
    "    iter_n = 1 # we will not iterate computations inside the inner loop\n",
    "    graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "    device = 'cuda'\n",
    "    \n",
    "    # this line runs the inner loop \n",
    "    gcn_result= gnn_torch_utils.run_gridsearch_batch_x(nodes_inner, FCs_inner, target_frs_inner, epochs, iter_n, graph_type, fit_param_list, device, chip_ids)\n",
    "    for_each_test_idx.append(gcn_result)   # collect the result of the inner loop         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we interrupted the above fitting step as it can take very long time.<br>\n",
    "Instead, the best performing parameters were uploaded to this repository under the path : '/gnn_prediction_sn/data/best_params'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing with the selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs_epoch': 250, 'bs_val': 0.7983556112478638, 'dropout_prob': 0.3, 'learning_rate': 0.005, 'weight_decay': 0.001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# load the best parameter set\n",
    "\n",
    "best_param = np.load('../data/best_params/sage_params_x_uniq_hd_20_corr_0.npy', allow_pickle=True).item()\n",
    "\n",
    "# example:\n",
    "print(best_param['sage1_max_0_max_p'][0]) # best parameter for the network 1 (index-wise 0) when using graphsage model with 1 conv. layer with max pooling.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bs_epoch' shows the best epoch that showed the best validation performance. <br>\n",
    "'bs_val' shows the resulting average MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param had 8 parameter sets which corresponds to the number of chips\n",
      "gnn_params now have 24 sets by repeating the parameter sets for each network\n"
     ]
    }
   ],
   "source": [
    "# repeat the same parameter set for test networks that belong to the same chip.\n",
    "\n",
    "gnn_params = gnn_torch_utils.match_network_param(best_param, chip_ids)\n",
    "\n",
    "print('best_param had {} parameter sets which corresponds to the number of chips'.format(len(best_param['sage1_max_0_max_p'])))\n",
    "print('gnn_params now have {} sets by repeating the parameter sets for each network'.format(len(gnn_params['sage1_max_0_max_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_acc: 1.3738, validate_acc : 0.5813, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9400, validate_acc : 0.4243, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8641, validate_acc : 0.3944, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8041, validate_acc : 0.3702, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7895, validate_acc : 0.3449, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3396\n",
      "Epoch: 0, train_acc: 1.1194, validate_acc : 0.1337, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9012, validate_acc : 0.1338, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8041, validate_acc : 0.1434, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7712, validate_acc : 0.1438, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7589, validate_acc : 0.1510, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1452\n",
      "Epoch: 0, train_acc: 1.1120, validate_acc : 1.2514, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8719, validate_acc : 1.1453, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8047, validate_acc : 1.1351, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7741, validate_acc : 1.1572, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7629, validate_acc : 1.1575, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1768\n",
      "Epoch: 0, train_acc: 1.0957, validate_acc : 2.0135, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8879, validate_acc : 2.1011, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7871, validate_acc : 2.0594, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7607, validate_acc : 2.0892, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7433, validate_acc : 2.0843, LR : 0.00500000\n",
      "iteration: 0, test_acc: 2.0773\n",
      "Epoch: 0, train_acc: 1.0055, validate_acc : 0.2786, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8306, validate_acc : 0.1852, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7974, validate_acc : 0.2033, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.2228\n",
      "Epoch: 0, train_acc: 1.0123, validate_acc : 0.3809, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8451, validate_acc : 0.2016, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8037, validate_acc : 0.1946, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1834\n",
      "Epoch: 0, train_acc: 1.3544, validate_acc : 0.8112, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9247, validate_acc : 0.1924, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8528, validate_acc : 0.1712, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8469, validate_acc : 0.1648, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8400, validate_acc : 0.1693, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1653\n",
      "Epoch: 0, train_acc: 1.0602, validate_acc : 0.4849, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9179, validate_acc : 0.3371, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8610, validate_acc : 0.3380, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8337, validate_acc : 0.3446, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8211, validate_acc : 0.3472, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3573\n",
      "Epoch: 0, train_acc: 1.3514, validate_acc : 1.0963, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9643, validate_acc : 0.1414, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.9080, validate_acc : 0.0937, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8695, validate_acc : 0.0948, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8515, validate_acc : 0.0849, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.0813\n",
      "Epoch: 0, train_acc: 1.0537, validate_acc : 1.2787, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8907, validate_acc : 1.1900, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8428, validate_acc : 1.1433, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8291, validate_acc : 1.1441, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8120, validate_acc : 1.1248, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1407\n",
      "Epoch: 0, train_acc: 1.0337, validate_acc : 2.1416, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8701, validate_acc : 1.8558, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8216, validate_acc : 1.7806, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.8236\n",
      "Epoch: 0, train_acc: 1.0817, validate_acc : 1.4548, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8863, validate_acc : 1.1203, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8082, validate_acc : 0.9801, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.9904\n",
      "Epoch: 0, train_acc: 1.0064, validate_acc : 2.2495, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8650, validate_acc : 1.9932, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8118, validate_acc : 1.8736, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.7548\n",
      "Epoch: 0, train_acc: 1.0861, validate_acc : 0.5675, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8711, validate_acc : 0.5141, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8080, validate_acc : 0.6191, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7790, validate_acc : 0.6910, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.7208\n",
      "Epoch: 0, train_acc: 1.0320, validate_acc : 1.2317, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8020, validate_acc : 1.1541, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7738, validate_acc : 1.1233, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7602, validate_acc : 1.1181, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7522, validate_acc : 1.1245, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7518, validate_acc : 1.1245, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7459, validate_acc : 1.1242, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7508, validate_acc : 1.1187, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7475, validate_acc : 1.1212, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7479, validate_acc : 1.1160, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7462, validate_acc : 1.1133, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7496, validate_acc : 1.1178, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7462, validate_acc : 1.1127, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7429, validate_acc : 1.1181, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7484, validate_acc : 1.1145, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7456, validate_acc : 1.1211, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7499, validate_acc : 1.1144, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7469, validate_acc : 1.1197, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7434, validate_acc : 1.1187, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7460, validate_acc : 1.1205, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.1211\n",
      "Epoch: 0, train_acc: 1.1607, validate_acc : 1.4962, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8210, validate_acc : 1.3389, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7857, validate_acc : 1.3502, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7741, validate_acc : 1.3449, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7650, validate_acc : 1.3439, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7577, validate_acc : 1.3317, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7498, validate_acc : 1.3447, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7522, validate_acc : 1.3333, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7503, validate_acc : 1.3302, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7523, validate_acc : 1.3361, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7506, validate_acc : 1.3460, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7495, validate_acc : 1.3376, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7467, validate_acc : 1.3526, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7466, validate_acc : 1.3545, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7483, validate_acc : 1.3456, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7487, validate_acc : 1.3431, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7461, validate_acc : 1.3434, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7454, validate_acc : 1.3484, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7484, validate_acc : 1.3533, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7447, validate_acc : 1.3451, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.3569\n",
      "Epoch: 0, train_acc: 1.1474, validate_acc : 2.4170, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8223, validate_acc : 2.0420, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7896, validate_acc : 1.9909, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7822, validate_acc : 2.0299, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7697, validate_acc : 2.0679, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7665, validate_acc : 2.0693, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7647, validate_acc : 2.0777, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7610, validate_acc : 2.0133, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7582, validate_acc : 2.0092, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7518, validate_acc : 2.0669, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7511, validate_acc : 2.0218, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7492, validate_acc : 2.0484, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7476, validate_acc : 2.0431, LR : 0.01000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, train_acc: 0.7469, validate_acc : 2.0826, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7481, validate_acc : 2.0330, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7481, validate_acc : 2.0102, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7476, validate_acc : 2.0428, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7494, validate_acc : 2.0631, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7480, validate_acc : 2.0423, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7506, validate_acc : 2.0185, LR : 0.01000000\n",
      "iteration: 0, test_acc: 2.0152\n",
      "Epoch: 0, train_acc: 1.2055, validate_acc : 0.9707, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8452, validate_acc : 1.0113, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7962, validate_acc : 0.9914, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.9960\n",
      "Epoch: 0, train_acc: 1.0222, validate_acc : 0.9232, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8298, validate_acc : 0.7882, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7850, validate_acc : 0.7385, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.7377\n",
      "Epoch: 0, train_acc: 1.0365, validate_acc : 0.5793, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8873, validate_acc : 0.4808, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8003, validate_acc : 0.4909, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.5011\n",
      "Epoch: 0, train_acc: 1.0093, validate_acc : 0.6096, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8291, validate_acc : 0.5255, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7653, validate_acc : 0.5634, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.5463\n",
      "Epoch: 0, train_acc: 1.0161, validate_acc : 1.0872, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8795, validate_acc : 1.0467, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8274, validate_acc : 0.9478, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8088, validate_acc : 0.9308, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.9365\n",
      "Epoch: 0, train_acc: 0.9848, validate_acc : 0.5101, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8561, validate_acc : 0.4096, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8062, validate_acc : 0.4131, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7925, validate_acc : 0.4285, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.4435\n",
      "Epoch: 0, train_acc: 1.0961, validate_acc : 0.6785, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8976, validate_acc : 0.5804, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8682, validate_acc : 0.5578, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8402, validate_acc : 0.5343, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.5152\n"
     ]
    }
   ],
   "source": [
    "# some parameters for running the grid search\n",
    "n_epoch = 1000 # this will be overriden when the n_epoch defined in the parameter set is lower.\n",
    "iter_n = 1 # for the paper, we iterated 30 times --> multiple runs with fixed random seed\n",
    "graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "device = 'cuda'\n",
    "\n",
    "sage_param = gnn_params['sage1_max_0_max_p']\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore') # for turning off np.array(dtype=object)  warning.\n",
    "gnn_result=gnn_torch_utils.run_GNN_batch_x(nodes, FCs, target_frs,n_epoch, iter_n, 'sage1_max', sage_param, device, chip_ids, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_train', 'mae_train', 'mse_test', 'mae_test', 'train_curve', 'validate_curve'])\n"
     ]
    }
   ],
   "source": [
    "# looking at the result\n",
    "\n",
    "print(gnn_result[0].keys()) # gnn result for network 1 (index 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of non-GNN models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the workflow is same with the GNN models, here we provide fitting scripts for the baseline model (average of target variables), linear regression and random forest regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_test', 'mse_train', 'mae_test', 'mae_train'])\n"
     ]
    }
   ],
   "source": [
    "import non_gnn_models\n",
    "importlib.reload(non_gnn_models)\n",
    "\n",
    "y_scale = 1 # boolean for standard scaling target variables as well\n",
    "\n",
    "# Baseline model\n",
    "baseline_result = non_gnn_models.average_mse_batch_x(target_frs, y_scale, chip_ids) \n",
    "print(baseline_result.keys()) # baseline model result of network 1 (index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['R-sq', 'slope_coef', 'mse_train', 'mae_train', 'pred', 'R-sq test', 'mse_test', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# linear regression model\n",
    "\n",
    "iter_n = 30 # 30 runs with the fixed random seed \n",
    "linear_result = non_gnn_models.linear_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids)\n",
    "print(linear_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reg_score', 'mse_train', 'y_pred', 'feat_importance', 'mse_test', 'mae_train', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# random forest regression model\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, False) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression model with a grid-searched parameter\n",
    "rf_param = np.load('../data/best_params/rf_batch_best_param_0.2_0_max_p_x.npy', allow_pickle=True).item() # grid-searched parameter for undirected FC tasks\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, False) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

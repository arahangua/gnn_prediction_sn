{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of GNN models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gnn_torch_utils' from '../pred_models/gnn_torch_utils.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# import util scripts\n",
    "# add path\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../pred_models/')\n",
    "\n",
    "import pred_utils\n",
    "import gnn_torch_utils\n",
    "import gnn_torch_models\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gnn_torch_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PCC', 'STTC', 'CCH'])\n",
      "dict_keys(['t1', 't2'])\n",
      "dict_keys(['nodes', 'fc_graphs', 'target_fr', 'chip_ids'])\n"
     ]
    }
   ],
   "source": [
    "# load-in data\n",
    "\n",
    "dataset = np.load('../data/dataset.npy', allow_pickle=True).item()\n",
    "print(dataset.keys())\n",
    "print(dataset['PCC'].keys())\n",
    "print(dataset['PCC']['t1'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'dataset' stores all the data used for the prediction task. <br>\n",
    "e.g.) dataset['PCC']['t1'] -> dataset for PCC and task1.\n",
    "\n",
    "'nodes' -> node features (waveform features, firing pattern features) <br>\n",
    "'fc_graphs'-> FC graphs <br>\n",
    "'target_fr' -> fold-changes in differential firing rates <br>\n",
    "'chip_ids' -> Microelectrode array id for each network. Used for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection (grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_prob': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# grid search with nested leave-one-out cross validation\n",
    "# Here we only put scripts to perform the grid search and we have uploaded the best parameter found after running this script.  \n",
    "\n",
    "# grid search parameters \n",
    "dropout_probs = [0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "l2_regs = [1e-4, 1e-3, 1e-2] \n",
    "hidden_dims = [8, 16, 32]\n",
    "\n",
    "#generate parameter sets\n",
    "fit_param_list = gnn_torch_utils.gen_gridparams(dropout_probs, learning_rates, l2_regs, hidden_dims)\n",
    "\n",
    "print(fit_param_list[0]) # print only the first parameter entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PCC task1 as an example \n",
    "\n",
    "# load in dataset\n",
    "nodes = dataset['PCC']['t1']['nodes']\n",
    "FCs = dataset['PCC']['t1']['fc_graphs']\n",
    "target_frs = dataset['PCC']['t1']['target_fr']\n",
    "chip_ids = dataset['PCC']['t1']['chip_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep. step for the nested cross validation \n",
    "\n",
    "# split dataset \n",
    "full_index= np.arange(len(target_frs)) # getting indices\n",
    "\n",
    "#get unique chip ids  (we have 24 networks from 8 different unique chips (for the undirected FC case))\n",
    "uniq_chip = np.unique(chip_ids)\n",
    "\n",
    "#sample one index per chip\n",
    "uniq_indices=[] \n",
    "for uniq_c in uniq_chip:\n",
    "    indices = np.where(np.array(chip_ids)==uniq_c)[0]\n",
    "    uniq_indices.append(indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main outer-inner loop\n",
    "for_each_test_idx = [] # placeholder to collect resulting MSEs (outer loop)\n",
    "for ii in uniq_indices: # we will not only take out the test network but also all networks that belong to the same chip for each inner loop. \n",
    "    same_chip = np.where(np.array(chip_ids) == chip_ids[ii])[0] \n",
    "    use_idx = np.setxor1d(full_index, same_chip)\n",
    "    \n",
    "    nodes_inner = np.array(nodes, dtype=object)[use_idx]\n",
    "    FCs_inner = np.array(FCs,dtype=object)[use_idx]\n",
    "    target_frs_inner = np.array(target_frs,dtype=object)[use_idx]\n",
    "    \n",
    "    \n",
    "    # some parameters for running the grid search\n",
    "    epochs = 1000 # we used 1000 for the paper. \n",
    "    iter_n = 1 # we will not iterate computations inside the inner loop\n",
    "    graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "    device = 'cuda'\n",
    "    \n",
    "    # this line runs the inner loop \n",
    "    gcn_result= gnn_torch_utils.run_gridsearch_batch_x(nodes_inner, FCs_inner, target_frs_inner, epochs, iter_n, graph_type, fit_param_list, device, chip_ids)\n",
    "    for_each_test_idx.append(gcn_result)   # collect the result of the inner loop         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we interrupted the above fitting step as it can take very long time.<br>\n",
    "Instead, the best performing parameters were uploaded to this repository under the path : '/gnn_prediction_sn/data/best_params'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing with the selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs_epoch': 250, 'bs_val': 0.7983556112478638, 'dropout_prob': 0.3, 'learning_rate': 0.005, 'weight_decay': 0.001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# load the best parameter set\n",
    "\n",
    "best_param = np.load('../data/best_params/sage_params_x_uniq_hd_20_corr_0.npy', allow_pickle=True).item()\n",
    "\n",
    "# example:\n",
    "print(best_param['sage1_max_0_max_p'][0]) # best parameter for the network 1 (index-wise 0) when using graphsage model with 1 conv. layer with max pooling.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bs_epoch' shows the best epoch that showed the best validation performance. <br>\n",
    "'bs_val' shows the resulting average MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param had 8 parameter sets which corresponds to the number of chips\n",
      "gnn_params now have 24 sets by repeating the parameter sets for each network\n"
     ]
    }
   ],
   "source": [
    "# repeat the same parameter set for test networks that belong to the same chip.\n",
    "\n",
    "gnn_params = gnn_torch_utils.match_network_param(best_param, chip_ids)\n",
    "\n",
    "print('best_param had {} parameter sets which corresponds to the number of chips'.format(len(best_param['sage1_max_0_max_p'])))\n",
    "print('gnn_params now have {} sets by repeating the parameter sets for each network'.format(len(gnn_params['sage1_max_0_max_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_acc: 1.5909, validate_acc : 0.5056, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9234, validate_acc : 0.4221, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8318, validate_acc : 0.4101, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7971, validate_acc : 0.3806, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7864, validate_acc : 0.3746, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3686\n",
      "Epoch: 0, train_acc: 1.0666, validate_acc : 0.3117, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9069, validate_acc : 0.2827, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8167, validate_acc : 0.2295, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7948, validate_acc : 0.1836, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7862, validate_acc : 0.1739, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1741\n",
      "Epoch: 0, train_acc: 1.0686, validate_acc : 1.3804, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8613, validate_acc : 1.1398, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7893, validate_acc : 1.0988, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7646, validate_acc : 1.1085, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7515, validate_acc : 1.1194, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1270\n",
      "Epoch: 0, train_acc: 1.1178, validate_acc : 2.4000, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8691, validate_acc : 2.0785, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7972, validate_acc : 2.1090, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7706, validate_acc : 2.1360, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7589, validate_acc : 2.1485, LR : 0.00500000\n",
      "iteration: 0, test_acc: 2.1872\n",
      "Epoch: 0, train_acc: 1.0046, validate_acc : 0.1175, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8530, validate_acc : 0.1937, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8022, validate_acc : 0.2000, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1853\n",
      "Epoch: 0, train_acc: 0.9991, validate_acc : 0.1832, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8489, validate_acc : 0.2046, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7926, validate_acc : 0.1716, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1807\n",
      "Epoch: 0, train_acc: 1.1350, validate_acc : 0.1552, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9150, validate_acc : 0.2290, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8331, validate_acc : 0.1974, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8167, validate_acc : 0.1781, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8064, validate_acc : 0.1828, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1842\n",
      "Epoch: 0, train_acc: 1.1096, validate_acc : 0.5226, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9178, validate_acc : 0.3394, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8873, validate_acc : 0.3328, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8556, validate_acc : 0.3411, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8352, validate_acc : 0.3634, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3609\n",
      "Epoch: 0, train_acc: 1.0583, validate_acc : 0.0773, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8741, validate_acc : 0.0966, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8217, validate_acc : 0.0938, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8057, validate_acc : 0.0894, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8004, validate_acc : 0.0932, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.0874\n",
      "Epoch: 0, train_acc: 1.1614, validate_acc : 1.5602, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9357, validate_acc : 1.2737, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8343, validate_acc : 1.1059, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8169, validate_acc : 1.1118, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8100, validate_acc : 1.1159, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1185\n",
      "Epoch: 0, train_acc: 1.0415, validate_acc : 2.0097, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8631, validate_acc : 1.8688, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7934, validate_acc : 1.6976, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.6634\n",
      "Epoch: 0, train_acc: 1.0532, validate_acc : 1.3444, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8880, validate_acc : 1.0617, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8283, validate_acc : 0.9854, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.9703\n",
      "Epoch: 0, train_acc: 1.1098, validate_acc : 1.8435, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8872, validate_acc : 1.9797, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8503, validate_acc : 1.9330, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.9420\n",
      "Epoch: 0, train_acc: 1.1322, validate_acc : 0.7461, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8677, validate_acc : 0.4722, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8102, validate_acc : 0.5733, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7867, validate_acc : 0.6537, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.7294\n",
      "Epoch: 0, train_acc: 1.0221, validate_acc : 1.2698, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.7908, validate_acc : 1.1152, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7718, validate_acc : 1.1319, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7638, validate_acc : 1.1144, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7605, validate_acc : 1.1278, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7557, validate_acc : 1.1313, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7553, validate_acc : 1.1385, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7554, validate_acc : 1.1392, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7544, validate_acc : 1.1462, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7506, validate_acc : 1.1455, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7525, validate_acc : 1.1350, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7515, validate_acc : 1.1486, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7476, validate_acc : 1.1349, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7509, validate_acc : 1.1344, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7522, validate_acc : 1.1414, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7521, validate_acc : 1.1376, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7515, validate_acc : 1.1332, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7499, validate_acc : 1.1312, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7489, validate_acc : 1.1380, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7495, validate_acc : 1.1239, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.1270\n",
      "Epoch: 0, train_acc: 1.0948, validate_acc : 1.4305, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8598, validate_acc : 1.2770, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7820, validate_acc : 1.3196, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7760, validate_acc : 1.3324, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7663, validate_acc : 1.3443, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7610, validate_acc : 1.3296, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7552, validate_acc : 1.3189, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7501, validate_acc : 1.3383, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7517, validate_acc : 1.3407, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7462, validate_acc : 1.3379, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7490, validate_acc : 1.3291, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7499, validate_acc : 1.3230, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7466, validate_acc : 1.3235, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7440, validate_acc : 1.3374, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7477, validate_acc : 1.3231, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7448, validate_acc : 1.3346, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7462, validate_acc : 1.3256, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7480, validate_acc : 1.3286, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7455, validate_acc : 1.3490, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7468, validate_acc : 1.3319, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.3480\n",
      "Epoch: 0, train_acc: 0.9889, validate_acc : 2.3184, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8298, validate_acc : 2.1370, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7862, validate_acc : 2.0559, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7751, validate_acc : 2.0767, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7666, validate_acc : 2.0590, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7602, validate_acc : 2.0664, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7581, validate_acc : 2.0839, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7538, validate_acc : 2.0747, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7503, validate_acc : 2.0886, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7484, validate_acc : 2.0692, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7457, validate_acc : 2.0685, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7508, validate_acc : 2.0758, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7477, validate_acc : 2.1158, LR : 0.01000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, train_acc: 0.7530, validate_acc : 2.0700, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7505, validate_acc : 2.1066, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7484, validate_acc : 2.0734, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7480, validate_acc : 2.0946, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7527, validate_acc : 2.0802, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7506, validate_acc : 2.1254, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7496, validate_acc : 2.0777, LR : 0.01000000\n",
      "iteration: 0, test_acc: 2.0390\n",
      "Epoch: 0, train_acc: 1.0728, validate_acc : 1.0675, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8160, validate_acc : 0.9755, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7670, validate_acc : 1.0300, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.0370\n",
      "Epoch: 0, train_acc: 1.0451, validate_acc : 0.9030, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8773, validate_acc : 0.8187, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8138, validate_acc : 0.7558, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.7427\n",
      "Epoch: 0, train_acc: 1.0049, validate_acc : 0.5762, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8448, validate_acc : 0.4498, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7915, validate_acc : 0.4885, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.5008\n",
      "Epoch: 0, train_acc: 1.6463, validate_acc : 1.3397, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.9045, validate_acc : 0.5369, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8090, validate_acc : 0.5361, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.5564\n",
      "Epoch: 0, train_acc: 1.0203, validate_acc : 1.2688, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8676, validate_acc : 1.0682, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8132, validate_acc : 0.9954, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7955, validate_acc : 0.9663, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.9621\n",
      "Epoch: 0, train_acc: 1.1165, validate_acc : 0.6458, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9233, validate_acc : 0.4491, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8721, validate_acc : 0.4045, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8380, validate_acc : 0.3922, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3978\n",
      "Epoch: 0, train_acc: 1.1879, validate_acc : 0.6608, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9109, validate_acc : 0.5469, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8199, validate_acc : 0.5410, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8000, validate_acc : 0.5315, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.5299\n"
     ]
    }
   ],
   "source": [
    "# some parameters for running the grid search\n",
    "n_epoch = 1000 # this will be overriden when the n_epoch defined in the parameter set is lower.\n",
    "iter_n = 1 # for the paper, we iterated 30 times --> multiple runs with fixed random seed\n",
    "graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "device = 'cuda'\n",
    "\n",
    "sage_param = gnn_params['sage1_max_0_max_p']\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore') # for turning off np.array(dtype=object)  warning.\n",
    "gnn_result=gnn_torch_utils.run_GNN_batch_x(nodes, FCs, target_frs,n_epoch, iter_n, 'sage1_max', sage_param, device, chip_ids, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_train', 'mae_train', 'mse_test', 'mae_test', 'train_curve', 'validate_curve'])\n"
     ]
    }
   ],
   "source": [
    "# looking at the result\n",
    "\n",
    "print(gnn_result[0].keys()) # gnn result for network 1 (index 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of non-GNN models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the workflow is same with the GNN models, here we provide fitting scripts for the baseline model (average of target variables), linear regression and random forest regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_test', 'mse_train', 'mae_test', 'mae_train'])\n"
     ]
    }
   ],
   "source": [
    "import non_gnn_models\n",
    "importlib.reload(non_gnn_models)\n",
    "\n",
    "y_scale = 1 # boolean for standard scaling target variables as well\n",
    "\n",
    "# Baseline model\n",
    "baseline_result = non_gnn_models.average_mse_batch_x(target_frs, y_scale, chip_ids) \n",
    "print(baseline_result.keys()) # baseline model result of network 1 (index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['R-sq', 'slope_coef', 'mse_train', 'mae_train', 'pred', 'R-sq test', 'mse_test', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# linear regression model\n",
    "\n",
    "iter_n = 30 # 30 runs with the fixed random seed \n",
    "linear_result = non_gnn_models.linear_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids)\n",
    "print(linear_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reg_score', 'mse_train', 'y_pred', 'feat_importance', 'mse_test', 'mae_train', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# random forest regression model\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, False) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reg_score', 'mse_train', 'y_pred', 'feat_importance', 'mse_test', 'mae_train', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# random forest regression model with a grid-searched parameter\n",
    "rf_param = np.load('../data/best_params/rf_batch_best_param_0.2_0_max_p_x.npy', allow_pickle=True) # grid-searched parameter for undirected FC tasks\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, rf_param) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

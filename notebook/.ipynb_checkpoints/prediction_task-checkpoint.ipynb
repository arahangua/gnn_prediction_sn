{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of GNN models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gnn_torch_utils' from '../pred_models/gnn_torch_utils.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# import util scripts\n",
    "# add path\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../pred_models/')\n",
    "\n",
    "import pred_utils\n",
    "import gnn_torch_utils\n",
    "import gnn_torch_models\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gnn_torch_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PCC', 'STTC', 'CCH'])\n",
      "dict_keys(['t1', 't2'])\n",
      "dict_keys(['nodes', 'fc_graphs', 'target_fr', 'chip_ids'])\n"
     ]
    }
   ],
   "source": [
    "# load-in data\n",
    "\n",
    "dataset = np.load('../data/dataset.npy', allow_pickle=True).item()\n",
    "print(dataset.keys())\n",
    "print(dataset['PCC'].keys())\n",
    "print(dataset['PCC']['t1'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'dataset' stores all the data used for the prediction task. <br>\n",
    "e.g.) dataset['PCC']['t1'] -> dataset for PCC and task1.\n",
    "\n",
    "'nodes' -> node features (waveform features, firing pattern features) <br>\n",
    "'fc_graphs'-> FC graphs <br>\n",
    "'target_fr' -> fold-changes in differential firing rates <br>\n",
    "'chip_ids' -> Microelectrode array id for each network. Used for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection (grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_prob': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# grid search with nested leave-one-out cross validation\n",
    "# Here we only put scripts to perform the grid search and we have uploaded the best parameter found after running this script.  \n",
    "\n",
    "# grid search parameters \n",
    "dropout_probs = [0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "l2_regs = [1e-4, 1e-3, 1e-2] \n",
    "hidden_dims = [8, 16, 32]\n",
    "\n",
    "#generate parameter sets\n",
    "fit_param_list = gnn_torch_utils.gen_gridparams(dropout_probs, learning_rates, l2_regs, hidden_dims)\n",
    "\n",
    "print(fit_param_list[0]) # print only the first parameter entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PCC task1 as an example \n",
    "\n",
    "# load in dataset\n",
    "nodes = dataset['PCC']['t1']['nodes']\n",
    "FCs = dataset['PCC']['t1']['fc_graphs']\n",
    "target_frs = dataset['PCC']['t1']['target_fr']\n",
    "chip_ids = dataset['PCC']['t1']['chip_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep. step for the nested cross validation \n",
    "\n",
    "# split dataset \n",
    "full_index= np.arange(len(target_frs)) # getting indices\n",
    "\n",
    "#get unique chip ids  (we have 24 networks from 8 different unique chips (for the undirected FC case))\n",
    "uniq_chip = np.unique(chip_ids)\n",
    "\n",
    "#sample one index per chip\n",
    "uniq_indices=[] \n",
    "for uniq_c in uniq_chip:\n",
    "    indices = np.where(np.array(chip_ids)==uniq_c)[0]\n",
    "    uniq_indices.append(indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main outer-inner loop\n",
    "for_each_test_idx = [] # placeholder to collect resulting MSEs (outer loop)\n",
    "for ii in uniq_indices: # we will not only take out the test network but also all networks that belong to the same chip for each inner loop. \n",
    "    same_chip = np.where(np.array(chip_ids) == chip_ids[ii])[0] \n",
    "    use_idx = np.setxor1d(full_index, same_chip)\n",
    "    \n",
    "    nodes_inner = np.array(nodes, dtype=object)[use_idx]\n",
    "    FCs_inner = np.array(FCs,dtype=object)[use_idx]\n",
    "    target_frs_inner = np.array(target_frs,dtype=object)[use_idx]\n",
    "    \n",
    "    \n",
    "    # some parameters for running the grid search\n",
    "    epochs = 1000 # we used 1000 for the paper. \n",
    "    iter_n = 1 # we will not iterate computations inside the inner loop\n",
    "    graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "    device = 'cuda'\n",
    "    \n",
    "    # this line runs the inner loop \n",
    "    gcn_result= gnn_torch_utils.run_gridsearch_batch_x(nodes_inner, FCs_inner, target_frs_inner, epochs, iter_n, graph_type, fit_param_list, device, chip_ids)\n",
    "    for_each_test_idx.append(gcn_result)   # collect the result of the inner loop         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we interrupted the above fitting step as it can take very long time.<br>\n",
    "Instead, the best performing parameters were uploaded to this repository under the path : '/gnn_prediction_sn/data/best_params'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing with the selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs_epoch': 250, 'bs_val': 0.7983556112478638, 'dropout_prob': 0.3, 'learning_rate': 0.005, 'weight_decay': 0.001, 'hidden_dims': 8}\n"
     ]
    }
   ],
   "source": [
    "# load the best parameter set\n",
    "\n",
    "best_param = np.load('../data/best_params/sage_params_x_uniq_hd_20_corr_0.npy', allow_pickle=True).item()\n",
    "\n",
    "# example:\n",
    "print(best_param['sage1_max_0_max_p'][0]) # best parameter for the network 1 (index-wise 0) when using graphsage model with 1 conv. layer with max pooling.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bs_epoch' shows the best epoch that showed the best validation performance. <br>\n",
    "'bs_val' shows the resulting average MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param had 8 parameter sets which corresponds to the number of chips\n",
      "gnn_params now have 24 sets by repeating the parameter sets for each network\n"
     ]
    }
   ],
   "source": [
    "# repeat the same parameter set for test networks that belong to the same chip.\n",
    "\n",
    "gnn_params = gnn_torch_utils.match_network_param(best_param, chip_ids)\n",
    "\n",
    "print('best_param had {} parameter sets which corresponds to the number of chips'.format(len(best_param['sage1_max_0_max_p'])))\n",
    "print('gnn_params now have {} sets by repeating the parameter sets for each network'.format(len(gnn_params['sage1_max_0_max_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_acc: 1.0559, validate_acc : 0.5463, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8778, validate_acc : 0.3871, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8270, validate_acc : 0.3735, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8005, validate_acc : 0.3618, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7854, validate_acc : 0.3592, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3595\n",
      "Epoch: 0, train_acc: 0.9825, validate_acc : 0.1810, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8548, validate_acc : 0.2430, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8034, validate_acc : 0.2147, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7767, validate_acc : 0.1970, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7638, validate_acc : 0.1738, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1481\n",
      "Epoch: 0, train_acc: 1.2737, validate_acc : 1.2393, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8594, validate_acc : 1.1449, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8066, validate_acc : 1.1394, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7844, validate_acc : 1.1473, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7722, validate_acc : 1.1602, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1660\n",
      "Epoch: 0, train_acc: 1.0575, validate_acc : 2.0634, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8679, validate_acc : 2.0021, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7988, validate_acc : 2.0030, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7762, validate_acc : 1.9777, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.7588, validate_acc : 1.9784, LR : 0.00500000\n",
      "iteration: 0, test_acc: 2.0089\n",
      "Epoch: 0, train_acc: 1.0216, validate_acc : 0.1627, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8614, validate_acc : 0.1818, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8073, validate_acc : 0.1984, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.2139\n",
      "Epoch: 0, train_acc: 1.0575, validate_acc : 0.1715, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8349, validate_acc : 0.1620, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.7936, validate_acc : 0.1538, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.1808\n",
      "Epoch: 0, train_acc: 1.0664, validate_acc : 0.5797, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9135, validate_acc : 0.2367, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8780, validate_acc : 0.2397, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8450, validate_acc : 0.2215, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8299, validate_acc : 0.2185, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.2014\n",
      "Epoch: 0, train_acc: 1.0754, validate_acc : 0.4671, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9003, validate_acc : 0.3565, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8432, validate_acc : 0.3557, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8234, validate_acc : 0.3603, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8126, validate_acc : 0.3544, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3648\n",
      "Epoch: 0, train_acc: 1.2192, validate_acc : 0.3937, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9664, validate_acc : 0.1152, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.9378, validate_acc : 0.0926, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.9007, validate_acc : 0.0851, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8501, validate_acc : 0.0846, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.0856\n",
      "Epoch: 0, train_acc: 1.2989, validate_acc : 1.3819, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.9560, validate_acc : 1.2836, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.9025, validate_acc : 1.2133, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8376, validate_acc : 1.1405, LR : 0.00500000\n",
      "Epoch: 200, train_acc: 0.8230, validate_acc : 1.1383, LR : 0.00500000\n",
      "iteration: 0, test_acc: 1.1565\n",
      "Epoch: 0, train_acc: 1.1282, validate_acc : 2.0432, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8787, validate_acc : 1.9458, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8392, validate_acc : 1.8794, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.8417\n",
      "Epoch: 0, train_acc: 1.1189, validate_acc : 1.3172, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8803, validate_acc : 1.1164, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8327, validate_acc : 0.9826, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.9611\n",
      "Epoch: 0, train_acc: 1.0501, validate_acc : 2.0951, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.9157, validate_acc : 2.1346, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8530, validate_acc : 2.0927, LR : 0.01000000\n",
      "iteration: 0, test_acc: 2.1334\n",
      "Epoch: 0, train_acc: 1.0649, validate_acc : 0.4367, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8798, validate_acc : 0.5091, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8202, validate_acc : 0.6491, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7923, validate_acc : 0.6924, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.7651\n",
      "Epoch: 0, train_acc: 1.0310, validate_acc : 1.2029, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8094, validate_acc : 1.1150, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7787, validate_acc : 1.1104, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7638, validate_acc : 1.1146, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7557, validate_acc : 1.1138, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7521, validate_acc : 1.1099, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7476, validate_acc : 1.1018, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7465, validate_acc : 1.1005, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7460, validate_acc : 1.1007, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7459, validate_acc : 1.1034, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7466, validate_acc : 1.1131, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7460, validate_acc : 1.1207, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7437, validate_acc : 1.1147, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7444, validate_acc : 1.1088, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7425, validate_acc : 1.1098, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7458, validate_acc : 1.1093, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7378, validate_acc : 1.1008, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7396, validate_acc : 1.1046, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7390, validate_acc : 1.0975, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7350, validate_acc : 1.1067, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.1026\n",
      "Epoch: 0, train_acc: 1.1160, validate_acc : 1.4539, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8698, validate_acc : 1.2989, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8145, validate_acc : 1.3071, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7947, validate_acc : 1.3330, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7724, validate_acc : 1.3120, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7596, validate_acc : 1.3324, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7530, validate_acc : 1.3507, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7537, validate_acc : 1.3502, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7457, validate_acc : 1.3462, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7434, validate_acc : 1.3556, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7438, validate_acc : 1.3570, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7471, validate_acc : 1.3452, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7429, validate_acc : 1.3556, LR : 0.01000000\n",
      "Epoch: 650, train_acc: 0.7444, validate_acc : 1.3600, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7461, validate_acc : 1.3363, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7453, validate_acc : 1.3513, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7431, validate_acc : 1.3616, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7422, validate_acc : 1.3597, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7414, validate_acc : 1.3665, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7438, validate_acc : 1.3581, LR : 0.01000000\n",
      "iteration: 0, test_acc: 1.3566\n",
      "Epoch: 0, train_acc: 1.0266, validate_acc : 2.3722, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.7935, validate_acc : 2.0132, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7701, validate_acc : 2.0118, LR : 0.01000000\n",
      "Epoch: 150, train_acc: 0.7621, validate_acc : 2.0010, LR : 0.01000000\n",
      "Epoch: 200, train_acc: 0.7599, validate_acc : 2.0272, LR : 0.01000000\n",
      "Epoch: 250, train_acc: 0.7562, validate_acc : 2.0244, LR : 0.01000000\n",
      "Epoch: 300, train_acc: 0.7585, validate_acc : 2.0106, LR : 0.01000000\n",
      "Epoch: 350, train_acc: 0.7510, validate_acc : 2.0445, LR : 0.01000000\n",
      "Epoch: 400, train_acc: 0.7448, validate_acc : 2.0558, LR : 0.01000000\n",
      "Epoch: 450, train_acc: 0.7416, validate_acc : 2.0785, LR : 0.01000000\n",
      "Epoch: 500, train_acc: 0.7472, validate_acc : 2.0765, LR : 0.01000000\n",
      "Epoch: 550, train_acc: 0.7376, validate_acc : 2.0726, LR : 0.01000000\n",
      "Epoch: 600, train_acc: 0.7387, validate_acc : 2.0561, LR : 0.01000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, train_acc: 0.7400, validate_acc : 2.0742, LR : 0.01000000\n",
      "Epoch: 700, train_acc: 0.7357, validate_acc : 2.0776, LR : 0.01000000\n",
      "Epoch: 750, train_acc: 0.7375, validate_acc : 2.1120, LR : 0.01000000\n",
      "Epoch: 800, train_acc: 0.7376, validate_acc : 2.0522, LR : 0.01000000\n",
      "Epoch: 850, train_acc: 0.7386, validate_acc : 2.0343, LR : 0.01000000\n",
      "Epoch: 900, train_acc: 0.7385, validate_acc : 2.0730, LR : 0.01000000\n",
      "Epoch: 950, train_acc: 0.7354, validate_acc : 2.1217, LR : 0.01000000\n",
      "iteration: 0, test_acc: 2.1115\n",
      "Epoch: 0, train_acc: 1.1296, validate_acc : 0.9387, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8546, validate_acc : 0.9749, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8002, validate_acc : 0.9804, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.9890\n",
      "Epoch: 0, train_acc: 1.0554, validate_acc : 0.9319, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8667, validate_acc : 0.8037, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8076, validate_acc : 0.7727, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.7519\n",
      "Epoch: 0, train_acc: 1.2910, validate_acc : 1.0061, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.8502, validate_acc : 0.4496, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.7882, validate_acc : 0.4819, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.4965\n",
      "Epoch: 0, train_acc: 1.4424, validate_acc : 0.9970, LR : 0.01000000\n",
      "Epoch: 50, train_acc: 0.9146, validate_acc : 0.5159, LR : 0.01000000\n",
      "Epoch: 100, train_acc: 0.8062, validate_acc : 0.5867, LR : 0.01000000\n",
      "iteration: 0, test_acc: 0.5821\n",
      "Epoch: 0, train_acc: 1.1280, validate_acc : 1.6717, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8815, validate_acc : 1.0619, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8398, validate_acc : 0.9787, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8269, validate_acc : 0.9569, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.9495\n",
      "Epoch: 0, train_acc: 0.9941, validate_acc : 0.6815, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8586, validate_acc : 0.4143, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8069, validate_acc : 0.4171, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.7909, validate_acc : 0.4027, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.3956\n",
      "Epoch: 0, train_acc: 1.0649, validate_acc : 0.6475, LR : 0.00500000\n",
      "Epoch: 50, train_acc: 0.8741, validate_acc : 0.5515, LR : 0.00500000\n",
      "Epoch: 100, train_acc: 0.8197, validate_acc : 0.5212, LR : 0.00500000\n",
      "Epoch: 150, train_acc: 0.8041, validate_acc : 0.5210, LR : 0.00500000\n",
      "iteration: 0, test_acc: 0.5681\n"
     ]
    }
   ],
   "source": [
    "# some parameters for running the grid search\n",
    "n_epoch = 1000 # this will be overriden when the n_epoch defined in the parameter set is lower.\n",
    "iter_n = 1 # for the paper, we iterated 30 times --> multiple runs with fixed random seed\n",
    "graph_type = 'sage1_max' # we will use graphsage model with 1 conv. layer using max pooling.\n",
    "device = 'cuda'\n",
    "\n",
    "sage_param = gnn_params['sage1_max_0_max_p']\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore') # for turning off np.array(dtype=object)  warning.\n",
    "gnn_result=gnn_torch_utils.run_GNN_batch_x(nodes, FCs, target_frs,n_epoch, iter_n, 'sage1_max', sage_param, device, chip_ids, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_train', 'mae_train', 'mse_test', 'mae_test', 'train_curve', 'validate_curve'])\n"
     ]
    }
   ],
   "source": [
    "# looking at the result\n",
    "\n",
    "print(gnn_result[0].keys()) # gnn result for network 1 (index 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing of non-GNN models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the workflow is same with the GNN models, here we provide fitting scripts for the baseline model (average of target variables), linear regression and random forest regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse_test', 'mse_train', 'mae_test', 'mae_train'])\n"
     ]
    }
   ],
   "source": [
    "import non_gnn_models\n",
    "importlib.reload(non_gnn_models)\n",
    "\n",
    "y_scale = 1 # boolean for standard scaling target variables as well\n",
    "\n",
    "# Baseline model\n",
    "baseline_result = non_gnn_models.average_mse_batch_x(target_frs, y_scale, chip_ids) \n",
    "print(baseline_result.keys()) # baseline model result of network 1 (index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['R-sq', 'slope_coef', 'mse_train', 'mae_train', 'pred', 'R-sq test', 'mse_test', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# linear regression model\n",
    "\n",
    "iter_n = 30 # 30 runs with the fixed random seed \n",
    "linear_result = non_gnn_models.linear_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids)\n",
    "print(linear_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reg_score', 'mse_train', 'y_pred', 'feat_importance', 'mse_test', 'mae_train', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# random forest regression model\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, False) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reg_score', 'mse_train', 'y_pred', 'feat_importance', 'mse_test', 'mae_train', 'mae_test'])\n"
     ]
    }
   ],
   "source": [
    "# random forest regression model with a grid-searched parameter\n",
    "rf_param = np.load('../data/best_params/rf_batch_best_param_0.2_0_max_p_x.npy', allow_pickle=True) # grid-searched parameter for undirected FC tasks\n",
    "\n",
    "iter_n = 1 # 1 run (with the fixed random seed) \n",
    "rf_result = non_gnn_models.rf_reg_batch_x(nodes, target_frs, iter_n, y_scale, chip_ids, rf_param) # rf regressor with default parameters\n",
    "print(rf_result[0].keys()) # R-sq is a R-sq value for the training data, R-sq test is a R-sq value for the testing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
